{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_Tutorial_Start.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8PEhbMy8Q-H"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/m2lschool/tutorials2021/blob/main/3_generative/VAE_Tutorial_Start.ipynb)\n",
        "\n",
        "Contact: {fviola@google.com, marco.ciccone@me.com}\n",
        "\n",
        "## Contents\n",
        "* Enabling TPUs in colab\n",
        "* Handling nested data structures using tree utilities in JAX\n",
        "* Distributing computation over multiple devices using *pmap*\n",
        "* Amortized variational inference (VAEs)\n",
        "  * Training VAEs optimizing ELBO\n",
        "  * Training $\\beta$-VAEs\n",
        "  * Training VAEs using constraint optimization (GECO)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xLj3uXiG0aG"
      },
      "source": [
        "# Set up your environment!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPZ737IgZU27"
      },
      "source": [
        "#@title Download and install all the missing packages required for this tutorial { display-mode: \"code\" }\n",
        "! pip install ipdb -q\n",
        "! pip install chex -q\n",
        "! pip install optax -q\n",
        "! pip install dm_haiku -q\n",
        "! pip install tfp-nightly[jax] -q\n",
        "! pip install tf-nightly -q\n",
        "! pip install livelossplot -q\n",
        "print(\"All packages installed!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk4fInRg8NWe"
      },
      "source": [
        "# @title Imports\n",
        "import inspect\n",
        "import os\n",
        "\n",
        "import chex\n",
        "import dill\n",
        "import functools\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import numpy as np\n",
        "import optax as tx\n",
        "import requests\n",
        "from pprint import pprint\n",
        "\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from livelossplot import PlotLosses\n",
        "from livelossplot.outputs import MatplotlibPlot\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability\n",
        "from tensorflow_probability.substrates import jax as tfp\n",
        "\n",
        "sns.set(rc={\"lines.linewidth\": 2.8}, font_scale=2)\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Returns the code of the python implementation of a given funciton as a string.\n",
        "get_code_as_string = lambda fn: dill.source.getsource(fn.__code__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3jP_DUzIdgq"
      },
      "source": [
        "# ------------------ #\n",
        "# Enable TPU support #\n",
        "# ------------------ #\n",
        "\n",
        "# This cell execution might take a while! don't worry :)\n",
        "# Don't forget to select a TPU or GPU runtime environment in\n",
        "# Runtime -> Change runtime type\n",
        "try:\n",
        "  if 'TPU_DRIVER_MODE' not in globals():\n",
        "    url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver_nightly'\n",
        "    resp = requests.post(url)\n",
        "    TPU_DRIVER_MODE = 1\n",
        "\n",
        "  # The following is required to use TPU Driver as JAX's backend.\n",
        "  from jax.config import config\n",
        "  config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "  config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
        "except:\n",
        "  print('TPUs not found. Enable a TPU runtime going to: '\n",
        "        '\"Runtime -> Change runtime type\"')\n",
        "devices = jax.devices()\n",
        "print(\"Available devices:\", devices)\n",
        "# Should print something like\n",
        "# Available devices: [TpuDevice(id=0, host_id=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, host_id=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, host_id=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, host_id=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, host_id=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, host_id=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, host_id=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, host_id=0, coords=(1,1,0), core_on_chip=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pt6BEKM-8vZ"
      },
      "source": [
        "# Warmup: bits and bobs\n",
        "\n",
        "Let's take a minute to look at some JAX functionality we will be using in this tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WETghW-t_PXg"
      },
      "source": [
        "## How to work with nested data with `jax.tree_utils`\n",
        "\n",
        "It is fairly common to structure data and parameters into nested formats, for example (nested) dictionaries, namedtuples, lists, dataclasses and variants thereof. For example, we might want to cleanly scope and group our model's variables by their component name into some dictionary-like format, like in Haiku, or in a Reinforcemente Learning setting we might want to explicitely lable the components of a rollout.\n",
        "\n",
        "Typically in our code we don't want to assume a priori any strucuture of the containers we are manipulating, and prefer code that can transparently handle arbitrary nested structures. Luckily JAX can natively do this for us, and we only need to familiarize ourselves with its `jax.tree_util` package, and make sure that our custom objects are registered with it (not to worry, we have libraries that do this for us!).\n",
        "\n",
        "You can find out more in the JAX `tree_util` package [documentation](https://jax.readthedocs.io/en/latest/jax.tree_util.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGMOcKeh_aOd"
      },
      "source": [
        "from collections import namedtuple \n",
        "data_container = namedtuple('data_box', 'component_a component_b')\n",
        "data = dict(\n",
        "    a=jnp.ones(shape=()),\n",
        "    b=[jnp.ones(shape=()),\n",
        "       data_container(jnp.ones(shape=()), jnp.ones(shape=()))],\n",
        "    c=(jnp.ones(shape=()), jnp.ones(shape=())))\n",
        "print('Structured data\\n', data)\n",
        "\n",
        "# We can use `jax.tree_map` to apply the same function to all the tensors\n",
        "# contained in a nested data structure.\n",
        "fn = lambda x: x * 2\n",
        "output = jax.tree_map(fn, data)\n",
        "print('Structure data, after {}'.format(get_code_as_string(fn)), output)\n",
        "\n",
        "# We can also call functions with multiple structured inputs, for example\n",
        "# parameters and gradients in an update step.\n",
        "fn = lambda x, y, delta=0.1: x + delta * y\n",
        "output = jax.tree_multimap(fn, data, data)\n",
        "print('Structure data, after {}'.format(get_code_as_string(fn)), output)\n",
        "\n",
        "# We can also 'flatten' the data to get a list of all the tensors contained in\n",
        "# the nested data structure.\n",
        "entries = jax.tree_leaves(data)\n",
        "print('Tree leaves\\n', entries)\n",
        "\n",
        "# We can 'unflatten' flattened data to get back the original strucure if we keep\n",
        "# around the original structure defintion.\n",
        "entries, tree_def = jax.tree_flatten(data)  # tree_def capture the structure\n",
        "data = jax.tree_unflatten(tree_def, entries)\n",
        "print('Flattened data\\n', entries)\n",
        "print('Unflattened data\\n', data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GqjhiZQFabr"
      },
      "source": [
        "# ------------------------ #\n",
        "# WARMUP OPTIONAL EXERCISE #\n",
        "# ------------------------ #\n",
        "\n",
        "# You have some batched data, structured in an unknow way and you want\n",
        "# to recover a list of unbatched data, structured the same way.\n",
        "# Write the code to do that using jax.tree_utils\n",
        "\n",
        "\n",
        "input_data = dict(\n",
        "    a=jnp.arange(3),\n",
        "    b=[jnp.arange(3),\n",
        "       data_container(jnp.arange(3), jnp.arange(3))],\n",
        "    c=(jnp.arange(3), jnp.arange(3)))\n",
        "\n",
        "print('Input data')\n",
        "pprint(input_data)\n",
        "\n",
        "def unbatch(data):\n",
        "  flattened_data, tree_def = jax.tree_flatten(data)\n",
        "  # ADD CODE BELOW \n",
        "  # -----------------------  \n",
        "  split_data = ... \n",
        "  unbatched_data = ...\n",
        "  # -----------------------\n",
        "  return unbatched_data\n",
        "\n",
        "print('\\nSplit data')\n",
        "pprint(unbatch(input_data))\n",
        "\n",
        "# Expected output: \n",
        "# Input data\n",
        "# {'a': DeviceArray([0, 1, 2], dtype=int32),\n",
        "#  'b': [DeviceArray([0, 1, 2], dtype=int32),\n",
        "#        data_box(component_a=DeviceArray([0, 1, 2], dtype=int32), component_b=DeviceArray([0, 1, 2], dtype=int32))],\n",
        "#  'c': (DeviceArray([0, 1, 2], dtype=int32),\n",
        "#        DeviceArray([0, 1, 2], dtype=int32))}\n",
        "\n",
        "# Split data\n",
        "# [{'a': DeviceArray([0], dtype=int32),\n",
        "#   'b': [DeviceArray([0], dtype=int32),\n",
        "#         data_box(component_a=DeviceArray([0], dtype=int32), component_b=DeviceArray([0], dtype=int32))],\n",
        "#   'c': (DeviceArray([0], dtype=int32), DeviceArray([0], dtype=int32))},\n",
        "#  {'a': DeviceArray([1], dtype=int32),\n",
        "#   'b': [DeviceArray([1], dtype=int32),\n",
        "#         data_box(component_a=DeviceArray([1], dtype=int32), component_b=DeviceArray([1], dtype=int32))],\n",
        "#   'c': (DeviceArray([1], dtype=int32), DeviceArray([1], dtype=int32))},\n",
        "#  {'a': DeviceArray([2], dtype=int32),\n",
        "#   'b': [DeviceArray([2], dtype=int32),\n",
        "#         data_box(component_a=DeviceArray([2], dtype=int32), component_b=DeviceArray([2], dtype=int32))],\n",
        "#   'c': (DeviceArray([2], dtype=int32), DeviceArray([2], dtype=int32))}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9ePo9Jm4U_s"
      },
      "source": [
        "## How to parallelize gradients computation over multiple devices using JAX.\n",
        "\n",
        "In JAX you can use the `pmap` primitive to parallelize computation over multiple devices; using reduction methods in `jax.lax` you can also have access to values aggregated across devices during the distributed computation, giving you a lot of flexibility over what you can achieve!\n",
        "\n",
        "For example, you can split a *large* batch over 8 TPU cores, compute partial \n",
        "gradients over the split batches and avarage them prior to updating\n",
        "the model parameters - in parallel - across all devices.\n",
        "\n",
        "Let's look at some example code of how this can be done.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwzp5tLReyhG"
      },
      "source": [
        "# ------- #\n",
        "# EXAMPLE #\n",
        "# ------- #\n",
        "\n",
        "# First off, let's verify that you that in this colab you should have access to \n",
        "# multiple TPU cores.\n",
        "num_dev = jax.local_device_count()\n",
        "print('Number of devices:\\n', num_dev, '\\n')\n",
        "\n",
        "# Let's define a simple data generation function, and an MSE loss for linear\n",
        "# regression.\n",
        "def get_data(prng_key, batch_size):\n",
        "  x_key, noise_key = jax.random.split(prng_key, 2)\n",
        "  x = jax.random.uniform(x_key, shape=(batch_size,1))\n",
        "  true_model = lambda x: x * 3 + 2 \n",
        "  noise = lambda key: jax.random.normal(key, shape=(batch_size, 1)) * 0.2\n",
        "  return jnp.concatenate([x, true_model(x) + noise(noise_key)], axis=1)\n",
        "\n",
        "def loss_fn(params, data):\n",
        "  prediction = params[0] * data[:, 0] + params[1]\n",
        "  target = data[:, 1]\n",
        "  return jnp.mean((prediction - target) ** 2)\n",
        "\n",
        "batch_size = 1024\n",
        "prng_key = jax.random.PRNGKey(0)\n",
        "data = get_data(prng_key, batch_size)\n",
        "params = jax.random.normal(prng_key, shape=(2,))\n",
        "\n",
        "# On a single core we can compute the gradients over a minibatch with:\n",
        "grad_fn = jax.grad(loss_fn)\n",
        "gradients = grad_fn(params, data)\n",
        "# and update the parameters using any update rule, like those you can find in\n",
        "# the optax package. \n",
        "\n",
        "# We now want to take advantage of the the multiple core made available to us. \n",
        "# To do so, we batch computation _over cores_.\n",
        "\n",
        "# We format the data and batch it twice, over cores and per-device core: \n",
        "data = get_data(prng_key, batch_size * num_dev)\n",
        "data = jnp.reshape(data, (num_dev, batch_size) + data.shape[1:])\n",
        "# Note that the leading dimension is now the number of cores!\n",
        "print('Data shape:\\n', data.shape, '\\n')\n",
        "\n",
        "# We provide each core with a copy of the parameters. Given an instance of the \n",
        "# params we can use JAX's broadcasting utility to achieve this.\n",
        "broadcast = lambda params: jnp.broadcast_to(params, (num_dev,) + params.shape)\n",
        "mapped_params = broadcast(params)\n",
        "# All the parameters copies are synced at the start of the model fitting; since\n",
        "# the udpates to the params will be the same, params will stay synced during\n",
        "# optimization.\n",
        "print('Params:\\n', params, '\\n')\n",
        "print('Mapped params:\\n', mapped_params, '\\n')\n",
        "\n",
        "# We then pmap the gradient fn, averaging the gradients computed across devices\n",
        "# using the pmap primitive and the jax.lax.pmean function.\n",
        "def get_averaged_grads(params, data):\n",
        "  grads = grad_fn(params, data)\n",
        "  grads = jax.lax.pmean(grads, axis_name='i')\n",
        "  return grads\n",
        "get_averaged_grads = jax.pmap(\n",
        "    get_averaged_grads, axis_name='i', devices=jax.devices())\n",
        "averaged_grads = get_averaged_grads(mapped_params, data)\n",
        "print('Averaged_grads:\\n', averaged_grads, '\\n')\n",
        "\n",
        "# Note that this is equivalent to mapping the gradient function and manually\n",
        "# averaging the result!\n",
        "get_mapped_grads = jax.pmap(grad_fn, axis_name='i', devices=jax.devices())\n",
        "mapped_grads = get_mapped_grads(mapped_params, data)\n",
        "print('Mapped_grads:\\n', mapped_grads, '\\n')\n",
        "print('Manually averaged_grads:\\n', jnp.mean(mapped_grads, axis=0), '\\n')\n",
        "\n",
        "# Of course we can pmap in one step, cleanly, much more complicated logic.\n",
        "# For example, the whole update step:\n",
        "optimizer = tx.sgd(1e-1)\n",
        "def update(params, opt_state, data):  \n",
        "  loss, grads = jax.value_and_grad(loss_fn)(params, data)\n",
        "  grads = jax.lax.pmean(grads, axis_name='i')\n",
        "  raw_updates, opt_state = optimizer.update(grads, opt_state)\n",
        "  params = tx.apply_updates(params, raw_updates)\n",
        "  return params, opt_state, loss\n",
        "# Note that pmap also compiles the function to XLA, akin to JIT!\n",
        "update = jax.pmap(update, axis_name='i', devices=jax.devices())\n",
        "opt_state = jax.tree_map(broadcast, optimizer.init(params))\n",
        "\n",
        "losses = []\n",
        "for _ in range(250):\n",
        "  prng_key, data_key = jax.random.split(prng_key)\n",
        "  data = get_data(prng_key, batch_size * num_dev)\n",
        "  data = jnp.reshape(data, (num_dev, batch_size) + data.shape[1:])\n",
        "  mapped_params, opt_state, loss = update(mapped_params, opt_state, data)\n",
        "  losses.append(jnp.mean(loss))\n",
        "  \n",
        "sz = 5; plt.figure(figsize=(4*sz,sz))\n",
        "plt.subplot(121)\n",
        "plt.plot(losses)\n",
        "plt.title('loss')\n",
        "plt.subplot(122)\n",
        "data = get_data(prng_key, 100)\n",
        "plt.scatter(data[:,0], data[:,1], label='data')\n",
        "plt.plot(\n",
        "    [0, 1],\n",
        "    [mapped_params[0, 1], mapped_params[0, 0] + mapped_params[0, 1]],\n",
        "    'r', label='prediction')\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cfQlEC07pal"
      },
      "source": [
        "# Get the data\n",
        "\n",
        "In this tutorial we will use the MNIST and Fashion MNIST datasets (and variations thereof). \n",
        "We can use TensorFlow data to download the data from the cloud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EHWPAsd7u50"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "mnist = tfds.load(\"mnist\")\n",
        "fashion_mnist = tfds.load(\"fashion_mnist\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyhvFtmloDWd"
      },
      "source": [
        "[Chex](https://github.com/deepmind/chex) is a library of utilities for helping to write reliable JAX code.\n",
        "\n",
        "Within `chex` you will find a `dataclass` object definition, which will automatically register new class instances into JAX, so you can easily apply JAX's tree utilities out of the box. We will use it to define a labelled data object type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmrdDH2ibvGG"
      },
      "source": [
        "@chex.dataclass\n",
        "class ContextualData(): \n",
        "  target: chex.Array\n",
        "  context: chex.Array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3loVhgk-H2b"
      },
      "source": [
        "# Here we provide some utilities for experiment and data visualization.\n",
        "\n",
        "def gallery(array, ncols=None):\n",
        "  \"\"\"Rearrange an array of images into a tiled layout.\"\"\"\n",
        "  nindex, height, width, num_channels = array.shape  \n",
        "  if ncols is None:\n",
        "    ncols = int(np.sqrt(nindex))    \n",
        "  nrows = int(np.ceil(nindex/ncols))  \n",
        "  pad = np.zeros((nrows*ncols-nindex, height, width, num_channels))\n",
        "  array = np.concatenate([array, pad], axis=0)\n",
        "  result = (array.reshape(nrows, ncols, height, width, num_channels)\n",
        "            .swapaxes(1,2)\n",
        "            .reshape(height*nrows, width*ncols, num_channels))\n",
        "  return result\n",
        "\n",
        "def imshow(x, title=''):\n",
        "  \"\"\"Shorthand for imshow.\"\"\"\n",
        "  plt.imshow(x[..., 0], cmap='gist_yarg', interpolation=None)\n",
        "  plt.axis('off')\n",
        "  plt.title(title)\n",
        "\n",
        "def custom_after_subplot(ax: plt.Axes, group_name: str, x_label: str):\n",
        "  \"\"\"Disable Legend in LiveLossPlot (interactive Matplotlib)\"\"\"\n",
        "  ax.set_title(group_name)\n",
        "  ax.set_xlabel(x_label)\n",
        "  ax.legend().set_visible(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezk2BhLaqDMD"
      },
      "source": [
        "# The datasets\n",
        "\n",
        "In this tuturial we will train _conditional_ models.\n",
        "As such, and as suggested by the `ContextualData` defintion, the dataset will provide targets and contexts. We will use two types of context, depending on the dataset.\n",
        "\n",
        "- **Simple**: for FashionMNIST the context will be the object class label, in one-hot format. \n",
        "- **Hard**: for MNIST digits we will make things a bit more interesting: the user will specify a simple function, mapping tuples of integers in the range `[0,9]` to an integer in `[0, 9]`, for example:\n",
        "```\n",
        "lambda i, j: (i + j) % 10\n",
        "```\n",
        "The context will be a tuple of images from MNIST whose labels will match the context integers, and the target will be an MNIST image of the corresponging\n",
        "output label. Hance, the result will be a dataset whose conditional context is potentially very rich and challenging to capture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKwY_jfDHZdy"
      },
      "source": [
        "# --------------------------------- #\n",
        "# SIMPLE context dataset generation #\n",
        "# --------------------------------- #\n",
        "\n",
        "def get_fashion_mnist(batch_size, data_split='train', seed=1, conditional=True):\n",
        "  def _preprocess(sample):\n",
        "    image = tf.cast(sample[\"image\"], tf.float32) / 255.0\n",
        "    context = tf.one_hot(sample[\"label\"], 10)    \n",
        "    # We can optionally make context constant, effectively making the dataset\n",
        "    # unconditional. This can be useful for debuggin purposes.\n",
        "    if not conditional:      \n",
        "      context *= 0\n",
        "    return ContextualData(target=image, context=context)\n",
        "    \n",
        "  ds = fashion_mnist[data_split]\n",
        "  ds = ds.map(map_func=_preprocess, \n",
        "              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(100000, seed=seed).repeat().batch(batch_size)\n",
        "  return iter(tfds.as_numpy(ds))\n",
        "\n",
        "# Visualize a sample of the data\n",
        "ds = next(get_fashion_mnist(batch_size=12))\n",
        "d = gallery(ds.target)\n",
        "imshow(d, title='Fashion MNIST targets')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA4MF2yLB-W4"
      },
      "source": [
        "# ------------------------------- #\n",
        "# HARD context dataset generation #\n",
        "# ------------------------------- #\n",
        "\n",
        "def get_raw_data(data_split='train'):\n",
        "  def _preprocess(sample):\n",
        "    image = tf.cast(sample[\"image\"], tf.float32) / 255.0\n",
        "    id = sample[\"label\"]\n",
        "    return image, id\n",
        " \n",
        "  ds = mnist[data_split]\n",
        "  ds = ds.map(map_func=_preprocess, \n",
        "              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(100000, seed=0).batch(2048)\n",
        "  images, labels = next(iter(tfds.as_numpy(ds)))\n",
        "\n",
        "  data_by_label = []\n",
        "  for i in range(10):\n",
        "    data_by_label.append(images[labels==i])\n",
        "  min_num = min([d.shape[0] for d in data_by_label])\n",
        "  return np.stack([d[:min_num] for d in data_by_label])\n",
        "\n",
        "\n",
        "def get_mnist_digits(batch_size,\n",
        "                     fn=None,\n",
        "                     data_split='train',\n",
        "                     max_num_examplars=None):\n",
        "  \"\"\"Instantiates a data generation function implementing the input fn in mnist.\n",
        "\n",
        "  Args:\n",
        "    batch_size: (int) batch size of the returned data\n",
        "    fn: (python function) default sum of two digits modulo 10, function from n\n",
        "        digits to a digit. The generator will return a batch of n + 1 digit\n",
        "        images whose labels correspont to inputs and output of the function.\n",
        "    data_split: (string) default 'train', crop of mnist to use for the data.\n",
        "    max_num_examplars: (int) maximum number of exemplars to be used - even when\n",
        "        not specified all digits will be represented by the same number of\n",
        "        exemplars.\n",
        "\n",
        "  Returns:\n",
        "    Function of JAX PRNG returning samples from mnist related to each other via\n",
        "    the user input fn function.\n",
        "  \"\"\"\n",
        "  raw_data = get_raw_data(data_split)\n",
        "  sz = raw_data.shape[1]\n",
        "  if max_num_examplars is not None:\n",
        "    sz = min(max_num_examplars, sz)\n",
        "\n",
        "  if fn is None:\n",
        "    # Examples\n",
        "    # fn = lambda i, j: (i + j) % 10\n",
        "    # fn = lambda i: (i + 1) % 10\n",
        "    fn = lambda i: (i + 1) % 10\n",
        "\n",
        "  num_inputs = len(inspect.signature(fn).parameters)\n",
        "  def data_fn(prng):\n",
        "    digit_prng, sample_prng = jax.random.split(prng, 2)\n",
        "    digit_indices = jax.random.randint(\n",
        "        digit_prng, shape=[batch_size, num_inputs], minval=0, maxval=10)\n",
        "    digit_indices = digit_indices.split(num_inputs, axis=1)\n",
        "    digit_indices += [fn(*digit_indices)]\n",
        "\n",
        "    sample_indices = jax.random.randint(\n",
        "        sample_prng, shape=[batch_size, num_inputs+1], minval=0, maxval=sz)\n",
        "    sample_indices = sample_indices.split(num_inputs + 1, axis=1)\n",
        "    samples = [raw_data[i[..., 0], j[..., 0], ...]\n",
        "               for i, j in zip(digit_indices, sample_indices)]\n",
        "    return samples\n",
        "\n",
        "  def generator(key=None):\n",
        "    if key is None:\n",
        "      key = jax.random.PRNGKey(0)\n",
        "    while True:\n",
        "      key, sample_key = jax.random.split(key)\n",
        "      data = data_fn(sample_key)\n",
        "      yield ContextualData(target=data[-1], context=data[:-1])\n",
        "\n",
        "  return generator\n",
        "\n",
        "def tile_context(context, filler_value=.2):\n",
        "  entries = [gallery(d) for d in data.context]\n",
        "  entry_shape = entries[0].shape\n",
        "  separator = np.full((entry_shape[0], 1, 1), filler_value) \n",
        "  entries = [\n",
        "    np.concatenate([e, separator], axis=1) for e in entries[:-1]] + entries[-1:] \n",
        "  return np.concatenate(entries, axis=1)\n",
        "\n",
        "# Visualize samples of target with hard context function \n",
        "context_fn = lambda x, y, z: (x + y + z) % 10\n",
        "data = next(get_mnist_digits(fn=context_fn, batch_size=16)())\n",
        "sz = 5\n",
        "plt.figure(figsize=(4 * sz, sz))\n",
        "plt.subplot(122)\n",
        "imshow(gallery(data.target),\n",
        "       'Target with ' + get_code_as_string(context_fn))\n",
        "plt.subplot(121)\n",
        "imshow(tile_context(data.context) , 'Context')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmLbpAW0uHuq"
      },
      "source": [
        "For convenience, we define a dataset constructor function taking a `hard` flag switching between the MNIST and Fashion MNIST datasets, as well a dummy dataset\n",
        "constructor that we will use for the purpose of retrieving shape information at graph construction time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eFPL0ag2aiY"
      },
      "source": [
        "def get_dataset(batch_size, num_dev, hard=False, data_split='train'):\n",
        "  # Instantiates the dataset adjusting the batch size to support training on \n",
        "  # multiple devices.\n",
        "  if hard: \n",
        "    dataset = get_mnist_digits(\n",
        "        batch_size=batch_size*num_dev, \n",
        "        data_split=data_split)()\n",
        "  else:\n",
        "    dataset = get_fashion_mnist(\n",
        "        batch_size=batch_size*num_dev, \n",
        "        data_split=data_split)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "def get_dummy_data(hard=False):\n",
        "  # Returns an instance of the data to gather shape info.\n",
        "  return next(get_dataset(batch_size=1, num_dev=1, hard=hard))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E54OTbDJ91h2"
      },
      "source": [
        "# Amortized variational inference (VAEs)\n",
        "\n",
        "Consider a joint distribution $p(x, z)$ over a set of latent variables $z \\in \\mathcal{Z}$ and observed variable $x \\in \\mathcal{X}$ (for instance, the images of our dataset).\n",
        "\n",
        "Making inference over the observed variable $x$ involves computing the posterior distribution $p(z|x) = p(x,z)/p(x)$ which is often intractable to compute, as the _marginal likelihood_ $p(x) = \\int_z p(x, z)dz$ requires integrating over a potentially exponential number of configurations of $z$. \n",
        "\n",
        "**Variational Inference (VI)** can be used to approximate the posterior $p(z|x)$ in a tractable fashion. VI casts the problem of computing the posterior as an optimization problem introducing a family of tractable (simpler) distributions $\\mathcal{Q}$ parametrized by $\\lambda$. The objective is to find the best approximation of the true posterior $q_{\\lambda^*} \\in \\mathcal{Q}$ that minimizes the Kullback-Leibler (KL) divergence with the exact prosterior: \n",
        "$$\n",
        "q_{\\lambda^*}(z) = \\underset{q_{\\lambda}}{arg min} \\ \\ D_{KL}(q_{\\lambda}(z) || p(z|x))\n",
        "$$\n",
        "\n",
        "$q_{\\lambda^*}(z)$ can serve as a proxy for the true posterior distribution. Note that the solution depends on the speciﬁc value of the observed (evidence) variables $x_i$ we are conditioning on, so computing the posterior requires solving an optimization problem for each sample independently.\n",
        "\n",
        "In this tutorial, we use a much more efficient approach. Rather than solving an optimization process per data point, we can **amortize the cost of inference** by leveraging the power of function approximation and learn a deterministic mapping to predict the distributional variables as a function of $x$. Specifically, the posterior parameters for $x_i$ will be the output of a *learned* function $f_\\theta(x_i)$, where $\\theta$ are parameters shared across all data points.\n",
        "\n",
        "<!-- Objective - maximize: \n",
        "\\begin{equation}\n",
        " \\mathbb{E}_{p^*(x)} \\mathbb{E}_{q(z|x)} \\log p_{\\theta}(x|z)  - \\mathbb{E}_{p^*(x)} KL(q(z|x)||p(z))\n",
        "\\end{equation} -->\n",
        "\n",
        "For more information, see: \n",
        "  * [Kingma and Welling, (2013), Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)\n",
        "  * [Kingma and Welling, (2019), An Introduction to Variational Autoencoders](https://arxiv.org/abs/1906.02691)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEyt2e2JvTcL"
      },
      "source": [
        "# Implement and train a (Conditional) Variational AutoEncoder\n",
        "\n",
        "Variational AutoEncoders (VAEs) are a powerful class of deep generative models with latent variables, comprising of three main components: an encoder, a decoder and a prior.  \n",
        "\n",
        "The encoder, also called *inference* or *recognition model*, computes the approximate posterior distribution $q_{\\phi}(z|x)$ of a given sample conditioned on $x$, while the decoder, or *generative model* reconstructs the sample starting from the latent variables $z$. In the conditional setting, the encoder and decoder will potentially also receive an additional conditioning input that we will refer to as _context_.\n",
        "\n",
        "When we have a unconditional generative model, we generally don't have control over the specific outputs produced by the model, and the generated samples could be anything depending on the sampled latent variable. Perhaps, a more useful generative process should allow one to influence specific characteristics of the samples to generate, for instance, based on a context variable $c$, e.g. a label or category. For this reason, in this tutorial, we focus on Conditional VAEs (CVAEs) where both the encoder and the decoder are conditioned on a context variable $c$.\n",
        "\n",
        "The main components of our model will be: \n",
        "\n",
        "* $P^*$ is the true data distribution. We have some samples from this in the form of a dataset.\n",
        "* $p(z)$ is a *prior* distribution over the latent space. In general the prior is simply $\\mathcal{N}(0, 1)$ but in our case we will *learn* a conditional prior distribution $p(z|c)$ based on the context.\n",
        "* $E(x, c)$ the encoder outputs distributions over the latent space $Z$, not just elements of it. The produced distribution is denoted $q_\\phi(z|x, c)$ and is the (approximate) *posterior* distribution.\n",
        "* $D(z, c)$ the decoder may be stochastic again, modeling the output distribution $p_\\theta(x|z, c)$.\n",
        "\n",
        "Now we go over the reconstruction and sampling process and finally motivate the losses used to train VAEs in this tutorial.\n",
        "\n",
        "### Reconstruction\n",
        "The process for reconstruction is:\n",
        "\n",
        "1. Take $x, c \\sim P^*$.\n",
        "2. Encode it $E_\\phi(x|c)$, yielding $q_\\phi(z|x, c)$.\n",
        "3. Sample a latent $z \\sim q_\\phi(z|x, c)$.\n",
        "4. Decode the latent $p_\\theta(\\hat{x}|z, c) = D_\\theta(z, c)$.\n",
        "5. Sample a reconstruction: $\\hat{x} \\sim p_\\theta(\\hat{x}|z, c)$.\n",
        "\n",
        "The prior has not showed up here, it plays a role in sampling.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1ENXCf3UkaGKy9sAi98w_cqafAb-UBRMw\" width=\"800\" alt=\"Illustration of conditional VAE reconstruction and sampling\" />\n",
        "<figcaption>Illustration of the conditional VAE architecture. <br> Credits: <a href=\"https://ijdykeman.github.io/ml/2016/12/21/cvae.html\"> https://ijdykeman.github.io/ml/2016/12/21/cvae.html</a></figcaption>\n",
        "</center>\n",
        "\n",
        "### Sampling\n",
        "The sampling process is:\n",
        "\n",
        "1. Given a context $c$, sample a latent $z \\sim p(z|c)$ from the conditional prior.\n",
        "2. Decode the latent $p_\\theta(x|z, c) = D_\\theta(z, c)$.\n",
        "3. Sample a reconstruction: $x \\sim p_\\theta(x|z, c)$.\n",
        "\n",
        "In practice we usually use simple, parametrizable distributions in the encoder and decoder. More specifically:\n",
        "\n",
        "**Encoder**\n",
        "Each latent dimension is a (univariate) gaussian, parametrized by mean and standard deviation. Note, this is the same as a multivariate guassian over the latent space with a diagional covariance matrix.\n",
        "\n",
        "**Decoder**\n",
        "We will quantize the pixels to 0 and 1, which allows us to use a Bernoulli distribution per pixel to model it. Though for visualizations we will continue to use grayscale values.\n",
        "\n",
        "\n",
        "## The Loss\n",
        "\n",
        "We use maximum likelihood for training, that is, ideally we would like to maximize:\n",
        "\n",
        "$$\\mathbb{E}_{x,c \\sim P^*}\\log p_{\\theta}(x|c).$$\n",
        "\n",
        "Note that $p_{\\theta}(x|c)$ is the marginal probability distribution $p_{\\theta}(x|c) = \\int p_\\theta(x, z|c) dz$. We can rewrite this in familiar terms as $\\int p_\\theta(x|z,c) p(z|c) dz$. However, computing (and maximizing) the above marginal is computationally infeasible.\n",
        "\n",
        "Instead, we can show\n",
        "\n",
        "$$\\log p_{\\theta}(x|c) \\ge \\mathbb{E}_{z \\sim q(z|x,c)} \\big[\\log p_\\theta(x | z,c)\\big] - \\mathbb{KL}\\big(q_\\phi(z | x,c) || p(z|c)\\big).$$\n",
        "\n",
        "This right hand side is called the evidence lower bound (ELBO). Broadly speaking the term variational methods, like variational inference, refers to this technique of using an approximate posterior distribution and the ELBO; this is where Variational Autoencoder gets its name from too.\n",
        "\n",
        "In order to try to maximize the likelihood, we maximize the ELBO instead. Recall from the lecture that under some conditions (that are not going to apply to us) the inequality is actually an equality. This yield the following loss used with Variational AutoEncoders:\n",
        "\n",
        "<font size=4>\n",
        "<br>\n",
        "<!-- $$ \\mathcal{L}(X, z) = \\mathbb{E}\\big[\\log P(X|z)\\big] - D_{KL}\\big[Q(z|X) \\big|\\big| P(z)\\big].$$ -->\n",
        "\n",
        "$$ \\mathcal{L}(x|c) = - \\Big( \\mathbb{E}_{z \\sim q(z|x, c)} \\big[\\log p_\\theta(x | z, c)\\big] - \\mathbb{KL}\\big(q_\\phi(z | x, c) || p(z|c)\\big) \\Big).$$\n",
        "</font>\n",
        "\n",
        "Observe that:\n",
        "* The first term encourages the model to reconstruct the input faithfully. This part is similar to the Vanilla AutoEncoder.\n",
        "* The second term can be seen as a *regularization term* of the encoder towards the prior.\n",
        "* Encoder, Decoder and Prior are conditioned on the context $c$. Removing the conditioning corresponds to recovering the original VAE formulation.\n",
        "\n",
        "(The formula contains an expectation; in practice that would be approximated with one or more samples.)\n",
        "\n",
        "## Implementation\n",
        "We start by defining the main VAE object class.\n",
        "\n",
        "We want to decouple its interface from how its components are defined; for example at this point we don't really care if we are using neural networks to implement the mapping from inputs to posterior.\n",
        "\n",
        "Some of the implementation will have to be `haiku` specific, but we will make an effort to restrict these details into the initialization functions. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekvgMkI4mKlh"
      },
      "source": [
        "def _transform(component):\n",
        "  return hk.without_apply_rng(hk.transform(component))\n",
        "\n",
        "# Sum-reduce on all dimensions but batch size\n",
        "_batch_sum = jax.vmap(jnp.sum) \n",
        "\n",
        "\n",
        "class VAE():\n",
        "  \"\"\"A (conditional) Variational Autoencoder.\n",
        "  \n",
        "  The class expects at construction time haiku modules implementing the\n",
        "  conditional {encoder, decoder, prior}, as well as context projector module.\n",
        "  \n",
        "  The encoder, decoder and prior use the output of the context projector\n",
        "  together with their other inputs to define distributions (posterior, output\n",
        "  and conditional prior respectively), implemented as tfp.distributions.\n",
        "\n",
        "  The context projector is used to map a potentially nested context to a single\n",
        "  condition tensor.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, *, encoder, decoder, prior, context_projector):\n",
        "    self._encoder = _transform(encoder)\n",
        "    self._decoder = _transform(decoder)\n",
        "    self._prior = _transform(prior)\n",
        "    self._context_projector = _transform(context_projector)\n",
        "\n",
        "  def init_params(self, prng, data):\n",
        "    prng_encoder, prng_decoder, prng_prior, prng_proj = jax.random.split(\n",
        "        prng, 4)\n",
        "    \n",
        "    # Initialize the context mapping.\n",
        "    # ADD CODE BELOW \n",
        "    # -----------------------\n",
        "    context_projector_params = ... \n",
        "    projected_context = ...\n",
        "    # -----------------------\n",
        "\n",
        "    # Initialize the conditional prior.\n",
        "    # ADD CODE BELOW \n",
        "    # -----------------------\n",
        "    prior_params = ...\n",
        "    z = ...\n",
        "    # -----------------------\n",
        "\n",
        "    # Initialize the encoder.\n",
        "    # ADD CODE BELOW \n",
        "    # -----------------------\n",
        "    encoder_params = ...\n",
        "    # -----------------------\n",
        "\n",
        "    # Initialize the decoder.\n",
        "    # ADD CODE BELOW \n",
        "    # -----------------------\n",
        "    decoder_params =  ...\n",
        "    # -----------------------\n",
        "\n",
        "    # Merge all the parameters into a single data structure.\n",
        "    params = hk.data_structures.merge(\n",
        "        context_projector_params, prior_params, encoder_params, decoder_params)\n",
        "    return params\n",
        "    \n",
        "  def sample(self, params, prng, context, mean=True):\n",
        "    prior_prng, decoder_prng = jax.random.split(prng)\n",
        "    # Map the context.\n",
        "    # ADD CODE BELOW \n",
        "    # -----------------------  \n",
        "    projected_context = ...\n",
        "    # -----------------------\n",
        "\n",
        "    # Get the conditional prior distribution, and take a sample from it.\n",
        "    # ADD CODE BELOW \n",
        "    # -----------------------\n",
        "    conditional_prior = ...\n",
        "    z = ...\n",
        "    # -----------------------\n",
        "\n",
        "    # Get the conditional output distribution.\n",
        "    # ADD CODE BELOW \n",
        "    # -----------------------\n",
        "    output_distribution = ...\n",
        "    # -----------------------\n",
        "    if mean:\n",
        "      return output_distribution.mean()\n",
        "    else:\n",
        "      return output_distribution.sample(seed=decoder_prng)\n",
        "\n",
        "  def sample_prior(self, params, prng, context):\n",
        "    projected_context = self._context_projector.apply(params, context)\n",
        "    conditional_prior = self._prior.apply(params, projected_context)\n",
        "    return conditional_prior.sample(seed=prng)\n",
        "\n",
        "  def decode(self, params, prng, z, context, mean=True):\n",
        "    projected_context = self._context_projector.apply(params, context)\n",
        "    output_distribution = self._decoder.apply(params, z, projected_context)\n",
        "    if mean:\n",
        "      return output_distribution.mean()\n",
        "    else:\n",
        "      return output_distribution.sample(seed=prng)\n",
        "\n",
        "  def reconstruct(self, params, prng, x, context, mean=True):\n",
        "    posterior_prng, decoder_prng = jax.random.split(prng)\n",
        "    # Map the context.\n",
        "    # ADD CODE BELOW \n",
        "    # -----------------------    \n",
        "    projected_context = ...\n",
        "    # -----------------------\n",
        "    \n",
        "    # Get the conditional posterior distribution p(z|x, context), and sample\n",
        "    # from it.\n",
        "    # ADD CODE BELOW\n",
        "    # -----------------------\n",
        "    posterior = ...\n",
        "    z = ...\n",
        "    # -----------------------\n",
        "\n",
        "    # Get the conditional output distribution. \n",
        "    # ADD CODE BELOW\n",
        "    # -----------------------\n",
        "    output_distribution = ...\n",
        "    # -----------------------\n",
        "    if mean:\n",
        "      return output_distribution.mean()\n",
        "    else:\n",
        "      return output_distribution.sample(seed=decoder_prng)\n",
        "\n",
        "  def stochastic_elbo(self, params, prng, x, context):\n",
        "    \"\"\"ELBO = log_p(x) - KL(q(z|x) || p(z)).\"\"\"\n",
        "    projected_context = self._context_projector.apply(params, context)    \n",
        "    z, kl = self._z_and_kl(params, prng, x, projected_context)\n",
        "    output_distribution = self._decoder.apply(params, z, projected_context)\n",
        "    # Sum reduce over signal domain (but not over batch!)\n",
        "    log_p_x = _batch_sum(output_distribution.log_prob(x))\n",
        "    elbo = log_p_x - kl\n",
        "    # Assemble all the stats that we want to log in an extra output dictionary.\n",
        "    extra_outputs = dict(kl=kl, log_p=log_p_x, elbo=elbo)\n",
        "    return elbo, extra_outputs\n",
        "\n",
        "  def kl(self, params, prng, x, context):\n",
        "    projected_context = self._context_projector.apply(params, context)\n",
        "    _, kl = self._z_and_kl(params, prng, x, projected_context)\n",
        "    return kl\n",
        "\n",
        "  def _z_and_kl(self, params, prng, x, projected_context):\n",
        "    \"\"\"Sample z and compute KL(q(z|x) || p(z)) = log_p(q(z|x)) - log_p(p(x)).\"\"\"\n",
        "\n",
        "    # Get the conditional prior, given the pre-projected context\n",
        "    # ADD CODE BELOW\n",
        "    # -----------------------\n",
        "    prior = ...\n",
        "    # -----------------------\n",
        "    \n",
        "    # Get the conditional posterior distribution p(z|x, context), and sample\n",
        "    # from it.  \n",
        "    # ADD CODE BELOW\n",
        "    # -----------------------\n",
        "    posterior = ...\n",
        "    z = ...\n",
        "    # -----------------------\n",
        "\n",
        "    # Compute the posterior log probability for the sampled z.\n",
        "    # Note _batch_sum: what is this doing?\n",
        "    log_q_z = _batch_sum(posterior.log_prob(z))\n",
        "    \n",
        "    # Compute prior log probability for the sampled z.\n",
        "    # ADD CODE BELOW\n",
        "    # -----------------------\n",
        "    log_p_z = ...\n",
        "    # -----------------------\n",
        "\n",
        "    # Compute the KL (see formula)\n",
        "    # ADD CODE BELOW\n",
        "    # -----------------------\n",
        "    kl = ...\n",
        "    # -----------------------\n",
        "    return z, kl\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwghDI92yqv2"
      },
      "source": [
        "Here we define all the utilities we will need to implement Haiku modules for the prior, encoder and decoder required to instantiate a VAE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S6eUGE_u37o"
      },
      "source": [
        "def _make_positive(x):\n",
        "  \"\"\"Transforms elementwise unconstrained inputs into positive outputs.\"\"\"\n",
        "  # The offset is such that the output will be equal to 1 whenever the input is\n",
        "  # equal to 0.\n",
        "  offset = jnp.log(jnp.exp(1.) - 1.)\n",
        "  return jax.nn.softplus(x + offset)\n",
        "  \n",
        "\n",
        "class DiagonalNormal(tfp.distributions.Normal):\n",
        "  \"\"\"Normal distribution with diagonal covariance.\"\"\"\n",
        "\n",
        "  def __init__(self, params, name='diagonal_normal'):\n",
        "    if params.shape[-1] != 2:\n",
        "      raise ValueError(\n",
        "          f'The last dimension of `params` must be 2, got {params.shape[-1]}.')\n",
        "    super().__init__(\n",
        "        loc=params[..., 0], scale=_make_positive(params[..., 1]), name=name)\n",
        "\n",
        "\n",
        "class ConditionalPrior(hk.Module):\n",
        "  \"\"\"A prior distribution whose parameters are computed by a conditioner.\"\"\"\n",
        "\n",
        "  def __init__(self, map_ctor, distribution, name='prior_net'):\n",
        "    super().__init__(name=name)  \n",
        "    # This function will map: (bs,) + context shape --> (bs, num_latents, 2)\n",
        "    self._map = map_ctor()\n",
        "    self._distribution = distribution\n",
        "\n",
        "  def __call__(self, context):\n",
        "    return self._distribution(self._map(context))\n",
        "\n",
        "\n",
        "class ConditionalEncoder(hk.Module):\n",
        "  \"\"\"A posterior distribution whose parameters are computed by a conditioner.\"\"\"\n",
        "\n",
        "  def __init__(self, map_ctor, distribution, name='posterior_net'):\n",
        "    super().__init__(name=name)\n",
        "    # This function will map inputs to the to posterior distribution parameters.\n",
        "    self._map = map_ctor()  \n",
        "    self._distribution = distribution\n",
        "\n",
        "  def __call__(self, x, context): \n",
        "    # We assume that x is an image and the context is flat.   \n",
        "    chex.assert_rank(x, 4)\n",
        "    chex.assert_rank(context, 2)     \n",
        "    \n",
        "    # Tile the context in order to be concatenated to the input tensor x.\n",
        "    # ADD CODE BELOW \n",
        "    # -----------------------\n",
        "    bs, height, width, _ = x.shape\n",
        "    context = ... \n",
        "    x_and_context = ...\n",
        "    # -----------------------\n",
        "\n",
        "    # Compute the posterior q(z|x, context) \n",
        "    return self._distribution(self._map(x_and_context))\n",
        "\n",
        "\n",
        "class ConditionalDecoder(hk.Module):\n",
        "  \"\"\"An output distribution whose parameters are computed by a conditioner.\"\"\"\n",
        "\n",
        "  def __init__(self, map_ctor, distribution, name='output_net'):\n",
        "    super().__init__(name=name)\n",
        "    # This function will map (z, context) to the to output distribution\n",
        "    # parameters.\n",
        "    self._map = map_ctor()\n",
        "    self._distribution = distribution\n",
        "\n",
        "  def __call__(self, z, context):\n",
        "    chex.assert_equal_shape_prefix([z, context], -1)\n",
        "    # Concatenate the context to the latents \n",
        "    # ADD CODE BELOW \n",
        "    # -------------------------------------------------------------\n",
        "    z_and_context = ...\n",
        "    # -------------------------------------------------------------\n",
        "    return self._distribution(self._map(z_and_context))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xvfdu2gzylj"
      },
      "source": [
        "Here we define how to assemble the VAE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HEAdV69u-RR"
      },
      "source": [
        "# -- Flat model \n",
        "def get_model(num_latents=50, num_hiddens=500, data_shape=[28, 28, 1]):\n",
        "  \"\"\"Creates a fully-connected VAE model.\"\"\"\n",
        "\n",
        "  def _build_map_to_latent_dist_params_net():\n",
        "    return hk.Sequential([\n",
        "        hk.Flatten(),\n",
        "        hk.nets.MLP([num_hiddens, num_hiddens, num_latents * 2]),\n",
        "        hk.Reshape([num_latents, 2]),\n",
        "    ])\n",
        "\n",
        "  def encoder_fn(*args, **kwargs):\n",
        "    return ConditionalEncoder(\n",
        "        map_ctor=_build_map_to_latent_dist_params_net,\n",
        "        distribution=DiagonalNormal)(*args, **kwargs)\n",
        "  \n",
        "  def prior_fn(*args, **kwargs):\n",
        "    return ConditionalPrior(\n",
        "        map_ctor=_build_map_to_latent_dist_params_net,\n",
        "        distribution=DiagonalNormal)(*args, **kwargs)\n",
        "\n",
        "  def _build_map_to_output_dist_params_net():\n",
        "    return hk.Sequential([\n",
        "        hk.Flatten(),\n",
        "        hk.nets.MLP([num_hiddens, num_hiddens, np.prod(data_shape)]),\n",
        "        hk.Reshape(data_shape),\n",
        "    ])\n",
        "\n",
        "  def decoder_fn(*args, **kwargs):\n",
        "    return ConditionalDecoder(\n",
        "        map_ctor=_build_map_to_output_dist_params_net,\n",
        "        distribution=tfp.distributions.Bernoulli)(*args, **kwargs)  \n",
        "    \n",
        "  def _concatenate(tensors):\n",
        "    proj = hk.nets.MLP([num_hiddens, num_latents])\n",
        "    data = []\n",
        "    for x in jax.tree_leaves(tensors):\n",
        "      if x.ndim > 2:\n",
        "        x = proj(hk.Flatten()(x))\n",
        "      # Note: this is not commutative!\n",
        "      # What could we do to make this projection commutative?\n",
        "      data.append(x)\n",
        "    data = jnp.concatenate(data, axis=-1)\n",
        "    return data\n",
        "\n",
        "  def proj_fn(*args):\n",
        "    \"\"\"Maps context inputs to conditioning tensor.\"\"\"\n",
        "    return hk.to_module(_concatenate)('context_projector')(*args)\n",
        "\n",
        "  return VAE(encoder=encoder_fn,\n",
        "             decoder=decoder_fn,\n",
        "             prior=prior_fn,\n",
        "             context_projector=proj_fn)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhmPt26y0xcK"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6abZ0QQz03Ig"
      },
      "source": [
        "## Shared hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suQ8L-zEbHZn"
      },
      "source": [
        "# @title Shared hyper-parameters\n",
        "\n",
        "# Model hyper-parameters: you can play around with these and see what changes!\n",
        "BATCH_SIZE = 128        #@param {type:'integer'}\n",
        "VIS_BATCH_SIZE = 64     #@param {type:'integer'}\n",
        "NUM_LATENTS = 30        #@param {type:'integer'}\n",
        "NUM_HIDDENS = 50        #@param {type:'integer'}\n",
        "TRAINING_STEPS = 1000   #@param {type:'integer'}\n",
        "USE_HARD_DATA = False   #@param {type:'boolean'}\n",
        "NUM_DEV = len(jax.local_devices())\n",
        "\n",
        "# Plot configs: no need to change them \n",
        "PLOT_REFRESH_EVERY = 50   #@param {type:'integer'}\n",
        "PLOT_EVERY = 5            #@param {type:'integer'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd7H4PgM1duQ"
      },
      "source": [
        "model = get_model(num_latents=NUM_LATENTS, num_hiddens=NUM_HIDDENS)\n",
        "\n",
        "# Once we have trained a model, we can explore its latent space by interpolating\n",
        "# (and decoding) between latents.\n",
        "def get_latent_interpolations(model, params, prng_key, num_steps, context):\n",
        "  start_key, stop_key, decoder_key = jax.random.split(prng_key, 3)\n",
        "  z_start = model.sample_prior(params, start_key, data.context)\n",
        "  z_stop = model.sample_prior(params, stop_key, data.context)\n",
        "  # To ensure that the interpolation is still likely under the Gaussian prior,\n",
        "  # we use Gaussian interpolation - rather than linear interpolation.\n",
        "  a = jnp.linspace(.0, 1.0, num_steps)\n",
        "  a = jnp.expand_dims(a, axis=1)\n",
        "  interpolations =  (jnp.sqrt(a) * z_start + jnp.sqrt(1 - a) * z_stop)\n",
        "  ncols = int(jnp.sqrt(num_steps))\n",
        "  context = jax.tree_map(\n",
        "      lambda x: jnp.tile(x, [num_steps] +  [1] *  (x.ndim-1)), data.context)\n",
        "  samples_from_interpolations = model.decode(\n",
        "      params, decoder_key, interpolations, context, mean=True)\n",
        "  return samples_from_interpolations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz4P1vzcMetd"
      },
      "source": [
        "# These are utilities for shape manipulation to facilitate training using pmap.\n",
        "@jax.jit\n",
        "def format_data(data):\n",
        "  return jax.tree_map(\n",
        "      lambda x: x.reshape((NUM_DEV, BATCH_SIZE) + x.shape[1:]), data)\n",
        "\n",
        "def setup_for_distributed_training(params, prng_key, opt_state, num_dev):\n",
        "  broadcast = lambda x: jnp.broadcast_to(x, (num_dev,) + x.shape)\n",
        "  (params, opt_state) = jax.tree_map(broadcast, (params, opt_state))\n",
        "  prng_key = jax.random.split(prng_key, num_dev)\n",
        "  return params, prng_key, opt_state\n",
        "\n",
        "get_slice = lambda x: jax.tree_map(lambda x: x[0], x)\n",
        "\n",
        "def reconstruct_and_sample(params, prng_key, model, data):\n",
        "  prng_key = prng_key[0]\n",
        "  params = get_slice(params)\n",
        "  sample_key, reconstruction_key, prng = jax.random.split(prng_key, 3)\n",
        "  reconstruction = model.reconstruct(\n",
        "      params, reconstruction_key, data.target, data.context)\n",
        "  sample = model.sample(params, sample_key, data.context)\n",
        "  return data.target, reconstruction, sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvcSd-ueZkzD"
      },
      "source": [
        "# Training a VAE optimizing ELBO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPbmUU_o0fn0"
      },
      "source": [
        "def get_elbo_loss_fn(model):\n",
        "  def elbo_loss_fn(params, prng, data):\n",
        "    elbo, stats = jax.tree_map(\n",
        "        jnp.mean, model.stochastic_elbo(params, prng, data.target, data.context))   \n",
        "    return -elbo, stats\n",
        "  return elbo_loss_fn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q73uv5tSv2v0"
      },
      "source": [
        "elbo_loss_fn = get_elbo_loss_fn(model)\n",
        "\n",
        "# Initialize the model\n",
        "prng_key = jax.random.PRNGKey(0)\n",
        "params = model.init_params(prng_key, get_dummy_data(hard=USE_HARD_DATA))\n",
        "\n",
        "# Instantiate and initialize the optimizer\n",
        "elbo_optimizer = tx.adam(1e-2)\n",
        "opt_state = elbo_optimizer.init(params)\n",
        "\n",
        "# Setup the optimizer state and params for distributed training \n",
        "params, prng_key, opt_state = setup_for_distributed_training(\n",
        "    params, prng_key, opt_state, num_dev=NUM_DEV)\n",
        "\n",
        "dataset = get_dataset(\n",
        "    batch_size=BATCH_SIZE, num_dev=NUM_DEV, hard=USE_HARD_DATA)\n",
        "\n",
        "# Define and pmap the update function\n",
        "def elbo_update(params, prng_key, opt_state, data):  \n",
        "  loss_key, prng_key = jax.random.split(prng_key)\n",
        "\n",
        "  # Use jax.value_and_grad to compute amd return all the outputs and the\n",
        "  # gradients for elbo_loss_fn (tip: what does the has_aux kwargs do?)\n",
        "  # ADD CODE BELOW \n",
        "  # -------------------------------------------------------------  \n",
        "  loss_outputs, grads = ... \n",
        "  # -------------------------------------------------------------\n",
        "\n",
        "  # Reduce-mean the gradients across devices.\n",
        "  # ADD CODE BELOW \n",
        "  # -------------------------------------------------------------  \n",
        "  grads = ...\n",
        "  # -------------------------------------------------------------  \n",
        "\n",
        "  # Perform an udpate step on the elbo_optimizer to produce parameter udpates,\n",
        "  # them apply the updates of the model params.\n",
        "  # ADD CODE BELOW \n",
        "  # -------------------------------------------------------------  \n",
        "  raw_updates, opt_state = ...\n",
        "  params = ...\n",
        "  # -------------------------------------------------------------  \n",
        "  return params, prng_key, opt_state, loss_outputs\n",
        "elbo_update = jax.pmap(elbo_update, axis_name='i', devices=jax.devices())\n",
        "\n",
        "\n",
        "# -- Set up logging and interactive plotting\n",
        "losses = []\n",
        "kls = []\n",
        "logps = []\n",
        "\n",
        "plot = PlotLosses(\n",
        "  groups={\n",
        "    'log p(x)': ['log_p'], \n",
        "    'KL': ['kl'],\n",
        "    'negative ELBO': ['negative ELBO']}, \n",
        "  outputs=[MatplotlibPlot(max_cols=3, after_subplot=custom_after_subplot)],\n",
        "  step_names='Iterations')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID2JuhlQh5V3"
      },
      "source": [
        "for step in range(TRAINING_STEPS):  \n",
        "  params, prng_key, opt_state, stats = elbo_update(\n",
        "      params, prng_key, opt_state, format_data(next(dataset)))\n",
        "\n",
        "  elbo = stats[1]['elbo'].mean()\n",
        "  kl = stats[1]['kl'].mean()\n",
        "  log_p = stats[1]['log_p'].mean()\n",
        "\n",
        "  if (step + 1) % PLOT_EVERY == 0:\n",
        "    plot.update({\n",
        "        'negative ELBO': -elbo,\n",
        "        'kl': kl,\n",
        "        'log_p': log_p\n",
        "    }, current_step=step)\n",
        "  if (step + 1) % PLOT_REFRESH_EVERY == 0:\n",
        "    plot.send()\n",
        "  \n",
        "  losses.append(elbo)\n",
        "  kls.append(kl)\n",
        "  logps.append(log_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9BwJgKK6Jxz"
      },
      "source": [
        "## Visualize reconstructions and samples\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg4X-0sg14pG"
      },
      "source": [
        "targets, reconstructions, samples = reconstruct_and_sample(\n",
        "    params, prng_key, model,\n",
        "    next(get_dataset(batch_size=VIS_BATCH_SIZE, num_dev=1, hard=USE_HARD_DATA,\n",
        "                     data_split='test')))\n",
        "\n",
        "sz = 6\n",
        "_ = plt.figure(figsize=((3*sz, 1*sz)))\n",
        "plt.subplot(131)\n",
        "imshow(gallery(targets), 'Targets')\n",
        "plt.subplot(132)\n",
        "imshow(gallery(reconstructions), 'Reconstructions')\n",
        "plt.subplot(133)\n",
        "imshow(gallery(samples), 'Conditional samples');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVxusk8L7ghe"
      },
      "source": [
        "## Explore the latent space\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsWl27VltqGq"
      },
      "source": [
        "data = get_dummy_data(hard=USE_HARD_DATA)\n",
        "num_steps = 7 * 7\n",
        "samples_from_interpolations = get_latent_interpolations(\n",
        "    model, get_slice(params), jax.random.PRNGKey(1), num_steps, data.context)\n",
        "\n",
        "sz = 6\n",
        "_ = plt.figure(figsize=((2*sz, sz)))\n",
        "plt.subplot(121)\n",
        "imshow(data.target[0,...], 'Label example')\n",
        "plt.subplot(122)\n",
        "imshow(gallery(samples_from_interpolations), 'Latent space interpolation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f4Dv2DwZssH"
      },
      "source": [
        "# Training a VAE with KL annealing\n",
        "\n",
        "Stochastic Variational Inference can get stuck in local optima since there is a certain tension between the likelihood and the KL terms. To ease the optimization, we could use a schedule fpr $\\beta$ where the KL coefficient is slowly annealed from $0$ to $1$ throughout training. This corresponds to weight more the reconstruction term at the beginning of the training and then move towards the fully stochastic variational objective. The modified objective becomes: \n",
        "\n",
        "<font size=4>\n",
        "<br>\n",
        "<!-- $$ \\mathcal{L}(X, z) = \\mathbb{E}\\big[\\log P(X|z)\\big] - D_{KL}\\big[Q(z|X) \\big|\\big| P(z)\\big].$$ -->\n",
        "\n",
        "$$ \\mathcal{L}(x|c) = - \\Big( \\mathbb{E}_{z \\sim q(z|x, c)} \\big[\\log p_\\theta(x | z, c)\\big] - \\beta \\ \\mathbb{KL}\\big(q_\\phi(z | x, c) || p(z|c)\\big) \\Big).$$\n",
        "</font>\n",
        "\n",
        "where the hyper-parameter $\\beta$ is annealed throughout optimization.\n",
        "\n",
        "**Tasks:**\n",
        "- Modify the training objective with a linear KL annealing schedule.\n",
        "- Look at the loss terms, what differences do you notice in their behaviours compared to the standard VAE objective?\n",
        "- Look at the reconstructions and samples during training. What do you see?\n",
        "\n",
        "</br>\n",
        "\n",
        "For more information, see: \n",
        "* [Bowman et al, (2015), Generating Sentences from a Continuous Space, (Section 3.1)](https://arxiv.org/abs/1511.06349)\n",
        "* [Sønderby et al, (2016), Ladder variational Autoencoder, (Section 2.3)](https://arxiv.org/abs/1602.02282)\n",
        "* [Burgess et al, (2018), Understanding disentangling in β-VAE](https://arxiv.org/abs/1804.03599)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7z1jIum0hyP"
      },
      "source": [
        "def get_beta_vae_loss_fn(model):  \n",
        "  def beta_vae_loss_fn(params, prng, beta, data):\n",
        "    _, loss_components = jax.tree_map(\n",
        "        jnp.mean, model.stochastic_elbo(\n",
        "            params, prng, data.target, data.context))\n",
        "    # The beta-VAE training loss function is a function of the beta\n",
        "    # hyper-parameter. Implement the loss using the components returned by \n",
        "    # the stochastic_elbo of the model class.\n",
        "    # elbo_loss_fn\n",
        "    # ADD CODE BELOW \n",
        "    # -------------------------------------------------------------  \n",
        "    loss = ... \n",
        "    # -------------------------------------------------------------  \n",
        "    return loss, loss_components\n",
        "  return beta_vae_loss_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjaxZ-cpZjTp"
      },
      "source": [
        "prng_key = jax.random.PRNGKey(0)\n",
        "params = model.init_params(prng_key, get_dummy_data(hard=USE_HARD_DATA))\n",
        "\n",
        "beta_vae_loss_fn = get_beta_vae_loss_fn(model)\n",
        "\n",
        "# Set up the optimzer and model like you did for the ELBO optimization\n",
        "# ADD CODE BELOW \n",
        "# -------------------------------------------------------------  \n",
        "beta_vae_optimizer = ... \n",
        "opt_state = ...\n",
        "params, prng_key, opt_state = ...\n",
        "dataset = ...\n",
        "  \n",
        "def beta_vae_update(params, prng_key, opt_state, beta, data):  \n",
        "  ... \n",
        "  return params, prng_key, opt_state, beta_vea_loss\n",
        "\n",
        "beta_vae_update = ...\n",
        "# -------------------------------------------------------------  \n",
        "\n",
        "\n",
        "# During the optimization of the beta-VAE we will be scheduling the value of \n",
        "# beta. Use optax's polynomial schedule to set up a linear schedule, e.g.\n",
        "# from 0.01 to 1.0 over TRAINING_STEPS//2 steps.\n",
        "# ADD CODE BELOW \n",
        "# -------------------------------------------------------------  \n",
        "beta_vae_current_step = ...\n",
        "initial_beta, final_beta = ...\n",
        "beta_schedule = ...\n",
        "# -------------------------------------------------------------  \n",
        "\n",
        "beta_vae_losses = []\n",
        "beta_vae_kls = []\n",
        "beta_vae_logps = []\n",
        "\n",
        "beta_vae_groups = {\n",
        "  'log p(x)': ['log_p'], \n",
        "  'kl': ['kl'],\n",
        "  'negative ELBO': ['negative ELBO'],\n",
        "  'beta': ['beta']\n",
        "}\n",
        "\n",
        "beta_vae_plot = PlotLosses(\n",
        "    groups=beta_vae_groups, \n",
        "    outputs=[MatplotlibPlot(max_cols=4, after_subplot=custom_after_subplot)], \n",
        "    step_names='Iterations')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyLT0ohCafS-"
      },
      "source": [
        "broadcast = lambda x: jnp.broadcast_to(x, (NUM_DEV,) + x.shape)\n",
        "\n",
        "for _ in range(TRAINING_STEPS):\n",
        "  beta_vae_current_step += 1\n",
        "  beta = beta_schedule(beta_vae_current_step)\n",
        "  # Since beta is varying during training, it cannot be statically compiled into\n",
        "  # udpate function and needs to be broadcast prior to being passed to the \n",
        "  # beta_vae_update.\n",
        "  params, prng_key, opt_state, stats = beta_vae_update(\n",
        "      params, prng_key, opt_state, broadcast(beta), format_data(next(dataset)))\n",
        "  \n",
        "  elbo = stats[1]['elbo'].mean()\n",
        "  kl = stats[1]['kl'].mean()\n",
        "  log_p = stats[1]['log_p'].mean()\n",
        "\n",
        "  if (beta_vae_current_step + 1) % PLOT_EVERY == 0:\n",
        "    beta_vae_plot.update({\n",
        "        'negative ELBO': -elbo,\n",
        "        'kl': kl,\n",
        "        'log_p': log_p,\n",
        "        'beta': beta\n",
        "    }, current_step=beta_vae_current_step)\n",
        "  if beta_vae_current_step % PLOT_REFRESH_EVERY == 0:\n",
        "    beta_vae_plot.send()\n",
        "  \n",
        "  beta_vae_losses.append(elbo)\n",
        "  beta_vae_kls.append(kl)\n",
        "  beta_vae_logps.append(log_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnGnxMkX6m9i"
      },
      "source": [
        "## Visualize reconstructions and samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lDFDAS55-Hw"
      },
      "source": [
        "targets, reconstructions, samples = reconstruct_and_sample(\n",
        "    params, prng_key, model,\n",
        "    next(get_dataset(batch_size=VIS_BATCH_SIZE, num_dev=1, hard=USE_HARD_DATA,\n",
        "                     data_split='test')))\n",
        "\n",
        "sz = 6\n",
        "_ = plt.figure(figsize=((3*sz, 1*sz)))\n",
        "plt.subplot(131)\n",
        "imshow(gallery(targets), 'Targets')\n",
        "plt.subplot(132)\n",
        "imshow(gallery(reconstructions), 'Reconstructions')\n",
        "plt.subplot(133)\n",
        "imshow(gallery(samples), 'Conditional samples');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf7C01sk6u0c"
      },
      "source": [
        "## Explore the latent space\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFNXWrUXAuxQ"
      },
      "source": [
        "data = get_dummy_data(hard=USE_HARD_DATA)\n",
        "num_steps = 7 * 7\n",
        "samples_from_interpolations = get_latent_interpolations(\n",
        "    model, get_slice(params), jax.random.PRNGKey(1), num_steps, data.context)\n",
        "\n",
        "sz = 6\n",
        "_ = plt.figure(figsize=((2*sz, sz)))\n",
        "plt.subplot(121)\n",
        "imshow(data.target[0,...], 'Label example')\n",
        "plt.subplot(122)\n",
        "imshow(gallery(samples_from_interpolations), 'Latent space interpolation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkCRFJ1sXlzp"
      },
      "source": [
        "# Constrained optimization\n",
        "\n",
        "Constrained optimization can be used to dynamically tune the relative weight of the likelihood and KL terms during optimization. \n",
        "This removes the need to manually tune $\\beta$, or create an optimization schedule, which can be problem specific.\n",
        "\n",
        "The objective now becomes:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\text{minimize } \\mathbb{E}_{p^*(x)} KL(q(z|x)||p(z)) \\text{ such that }  \\mathbb{E}_{p^*(x)} \\mathbb{E}_{q(z|x) \\log p_\\theta(x|z)} > \\kappa \n",
        "\\end{equation}\n",
        "\n",
        "This can be solved using Lagrange multipliers. The objective then becomes:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\text{minimize }  \\mathbb{E}_{p^*(x)} KL(q(z|x)||p(z)) + \\lambda  (\\mathbb{E}_{p^*(x)} \\mathbb{E}_{q(z|x)} (\\kappa - \\log p_\\theta(x|z)))\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "The difference compared to the KL annealing is that:\n",
        "\n",
        "   * $\\lambda$ is a learned parameter - it will be learned using stochastic gradient descent, like the network parameters.  The difference is that the lagrangian has to solve a maximization problem. You can see this intuitively: the graadient with respect to $\\lambda$ in the objective above is $\\mathbb{E}_{p^*(x)} \\mathbb{E}_{q(z|x)} (\\alpha - \\log p_\\theta(x|z))$. If $ \\mathbb{E}_{p^*(x)} \\mathbb{E}_{q(z|x)} (\\alpha - \\log p_\\theta(x|z))> 0$, the constraint is not being satisfied, so the value of the lagrangian needs to increase. This will be done by doing gradient ascent, instead of gradient descent. Note that for $\\lambda$ to be a valid lagranian in a minimization problem, it has to be positive.\n",
        "   * The practicioner has to specify the hyperparameter $\\kappa$, which determines the reoncstruction quality of the model.\n",
        "   * the coefficient is in front of the likelihood term, not the KL term. This is mainly for convenience, as it is easier to specify the hyperparameter $\\kappa$ for the likelihood (reconstruction loss).\n",
        "\n",
        "For more assumptions made by this method, see the Karush–Kuhn–Tucker conditions.\n",
        "\n",
        "For more information, see: \n",
        "  * http://bayesiandeeplearning.org/2018/papers/33.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0aSoWHFV-GI"
      },
      "source": [
        "## Lagrange multipliers for constrained optimization\n",
        "\n",
        "This is a reimplementation in JAX of the [constrained optimization tools](https://github.com/deepmind/sonnet/blob/master/sonnet/python/modules/optimization_constraints.py) found in Sonnet v1.\n",
        "\n",
        "Note the peculiar implementation of the `clip` function, which is used to limit the valid range of the multipliers; this is used for example to force their values to be non-negative, or to limit their maximum values to control the interaction of the loss components during training.\n",
        "\n",
        "In this implementation the gradients flowing through the clipping function are not set to 0 when above and below the thresholds, if the gradients would make the inputs move towards the valid range. This is particularly useful when setting a maximum valid value, since it allows for the multipliers to become smaller once the constraints are (eventually) satisfied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj186VkXV1Fh"
      },
      "source": [
        "@functools.partial(jax.custom_vjp, nondiff_argnums=(1, 2, 3))\n",
        "def clip(x, min_val, max_val, maximize=True):\n",
        "  del maximize\n",
        "  return jax.tree_map(lambda e: jnp.clip(e, min_val, max_val), x)\n",
        "\n",
        "\n",
        "def clip_fwd(x, min_val, max_val, maximize):\n",
        "  return clip(x, min_val, max_val, maximize), x\n",
        "\n",
        "\n",
        "def clip_bwd(min_val, max_val, maximize, x, co_tangents):\n",
        "  zeros = jax.tree_map(jnp.zeros_like, co_tangents)\n",
        "  if min_val is not None:\n",
        "    get_mask = lambda x, v, t: (x < v) & (t < 0 if maximize else t > 0)\n",
        "    mask = jax.tree_multimap(get_mask, x, min_val, co_tangents)\n",
        "    co_tangents = jax.tree_multimap(jnp.where, mask, zeros, co_tangents)\n",
        "  if max_val is not None:\n",
        "    get_mask = lambda x, v, t: (x > v) & (t > 0 if maximize else t < 0)\n",
        "    mask = jax.tree_multimap(get_mask, x, max_val, co_tangents)\n",
        "    co_tangents = jax.tree_multimap(jnp.where, mask, zeros, co_tangents)\n",
        "  return co_tangents,\n",
        "\n",
        "\n",
        "clip.defvjp(clip_fwd, clip_bwd)\n",
        "\n",
        "\n",
        "class LagrangeMultiplier(hk.Module):\n",
        "  \"\"\"Lagrange Multiplier module for constrained optimization.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               shape=(),\n",
        "               initializer=1.0,\n",
        "               maximize=True,\n",
        "               valid_range=None,\n",
        "               name='lagrange_multiplier'):\n",
        "    super().__init__(name=name)\n",
        "    self._shape = shape\n",
        "    if callable(initializer):\n",
        "      self._initializer = initializer\n",
        "    else:\n",
        "      self._initializer = lambda *args: jnp.ones(*args) * initializer\n",
        "    self._maximize = maximize\n",
        "    self._valid_range = valid_range if valid_range is not None else (0.0, None)\n",
        "    assert self._valid_range[0] >= 0\n",
        "\n",
        "  def __call__(self):\n",
        "    lag_mul = hk.get_parameter('w', self._shape, init=self._initializer)\n",
        "    lag_mul = clip(lag_mul, *self._valid_range, maximize=self._maximize)\n",
        "    return lag_mul"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l3Ni4tW7IZ3"
      },
      "source": [
        "## Training a VAE using GECO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rS27R4sXTRE"
      },
      "source": [
        "def get_geco_loss(prng, model, kappa, valid_range, init_lambda):\n",
        "\n",
        "  def constraint_term(x, target):    \n",
        "    lag_mul = LagrangeMultiplier(\n",
        "        shape=x.shape, valid_range=valid_range, initializer=init_lambda)()\n",
        "    return jnp.sum(lag_mul * (x - target)), lag_mul\n",
        "  constraint_term = _transform(constraint_term)\n",
        "  lagmul_params = constraint_term.init(prng, jnp.ones(()), jnp.ones(()))\n",
        "\n",
        "  def geco_loss(params, prng, data):\n",
        "    \"\"\"Loss using constrained optimization as in GECO.\"\"\"\n",
        "    # Compute the KL term (make sure to average across the batch!)\n",
        "    # ADD CODE BELOW \n",
        "    # -----------------------\n",
        "    kl = ... \n",
        "    # -----------------------\n",
        "\n",
        "    # Reconstruct the inputs and compute the reconstruction error (e.g. MSE)\n",
        "    # ADD CODE BELOW \n",
        "    # -----------------------  \n",
        "    reconstruction = ...\n",
        "    reconstruction_err = ...\n",
        "    # -----------------------\n",
        "\n",
        "    # If you didn't use MSE before, you need to adjust the kappa term in the\n",
        "    # constraint definition.\n",
        "    constraint_satisfaction, lag_mul = constraint_term.apply(\n",
        "        params, reconstruction_err, np.prod(data.target.shape[1:]) * kappa**2)\n",
        "    loss = constraint_satisfaction + kl\n",
        "    metrics = {\n",
        "        'loss': loss, \n",
        "        'mse': jnp.mean((reconstruction - data.target)**2),\n",
        "        'kl': kl,\n",
        "        'lag_mul': lag_mul}\n",
        "    return loss, metrics\n",
        "\n",
        "  return geco_loss, lagmul_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v8QtWUX10aK"
      },
      "source": [
        "prng_key = jax.random.PRNGKey(0)\n",
        "kappa = 0.18\n",
        "valid_range = (0, 4.0)\n",
        "init_lambda = 2.0\n",
        "\n",
        "params = model.init_params(prng_key, get_dummy_data(hard=USE_HARD_DATA))\n",
        "geco_loss_fn, lagmul_params = get_geco_loss(\n",
        "    prng_key, model, kappa, valid_range, init_lambda=init_lambda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZUngLFyxIst"
      },
      "source": [
        "## Using multiple optimizers jointly\n",
        "\n",
        "We will now see how we can optimize joinlty the model parameters `params` and the Lagrange multipliers `lagmul_params`.\n",
        "\n",
        "We want to update the Lagrange multipliers via stochastic gradient *ascent*; for example we could consider using the logic in `tx.sgd` with a *negative* learning rate. The model params will be instead optimized using ADAM, just like in the previous cells.\n",
        "\n",
        "In the next cell you will find a handy wrapper to capture multiple optimizers into a single optax object. \n",
        "\n",
        "What is left to do is:\n",
        "\n",
        "1.   Merge all the parameters into a single tree; you can do so using the `hk.data_structures.merge` utility in Haiku:\n",
        "\n",
        "  ```\n",
        "  params = hk.data_structures.merge(params, lagmul_params)\n",
        "  ```\n",
        "2.   Specify how to filter the resulting `params` structure to select which variables should be mapped to which optimizer. Tip: you can filter the Lagrange multipliers with:\n",
        "  ```\n",
        "  multiplier_filter = lambda m, n, p: 'lagrange' in m\n",
        "  ```\n",
        "  and the model variables with:\n",
        "  ```\n",
        "  model_params_filter = lambda m, n, p: 'lagrange' not in m\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhqqfnHRWRcA"
      },
      "source": [
        "def multi_opt(**filter_optimizer_map):\n",
        "  \"\"\"Wraps multiple optimizers within an object with the optax interface.\n",
        "\n",
        "  Args:\n",
        "    **filter_optimizer_map: kwargs used to map optimizer names to\n",
        "    (predicate, optimizer) tuples, where predicate is a function which will be\n",
        "    passed to haiku.data_structure.filter in order to select which variables\n",
        "    are to be updated by the corresponding optimizer.\n",
        "\n",
        "  Returns:\n",
        "    An optax.InitUpdate tuple.\n",
        "  \"\"\"\n",
        "  def filter_(predicate, params):\n",
        "    if params is None:\n",
        "      return None\n",
        "    return hk.data_structures.filter(predicate, params)\n",
        "\n",
        "  merge_ = hk.data_structures.merge\n",
        "\n",
        "  def _init(params):\n",
        "    opt_state = dict()\n",
        "    for opt_name, (predicate, opt) in filter_optimizer_map.items():\n",
        "      opt_state[opt_name] = opt.init(filter_(predicate, params))\n",
        "    return opt_state\n",
        "\n",
        "  def _update(updates, state, params=None):\n",
        "    new_updates = {}\n",
        "    new_state = dict()\n",
        "    for opt_name, (predicate, opt) in filter_optimizer_map.items():\n",
        "      update, new_state[opt_name] = opt.update(\n",
        "          filter_(predicate, updates), state[opt_name],\n",
        "          filter_(predicate, params))\n",
        "      new_updates = merge_(new_updates, update)\n",
        "    return new_updates, new_state\n",
        "\n",
        "  return tx.InitUpdate(_init, _update)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHQGFLJnxEnh"
      },
      "source": [
        "# Merge them using hk.data_structures.merge\n",
        "# function.\n",
        "# ADD CODE BELOW \n",
        "# -----------------------\n",
        "params = ... \n",
        "# -----------------------\n",
        "\n",
        "# Optimize the Lagrange multipliers via stochastic gradient ascent.\n",
        "# Optimize the model params will be optimized using ADAM.\n",
        "# ADD CODE BELOW \n",
        "# -----------------------\n",
        "geco_optimizer = ...\n",
        "opt_state = ...\n",
        "# -----------------------\n",
        "\n",
        "params, prng_key, opt_state = setup_for_distributed_training(\n",
        "    params, prng_key, opt_state, num_dev=NUM_DEV)\n",
        "\n",
        "dataset = get_dataset(\n",
        "    batch_size=BATCH_SIZE, num_dev=NUM_DEV, hard=USE_HARD_DATA)\n",
        "\n",
        "def geco_update(params, prng_key, opt_state, data):\n",
        "  loss_key, prng_key = jax.random.split(prng_key)\n",
        "  geco_loss, grads = jax.value_and_grad(\n",
        "      geco_loss_fn, has_aux=True)(params, loss_key, data)\n",
        "  grads = jax.lax.pmean(grads, axis_name='i')\n",
        "  raw_updates, opt_state = geco_optimizer.update(grads, opt_state)\n",
        "  params = tx.apply_updates(params, raw_updates)\n",
        "  return params, prng_key, opt_state, geco_loss\n",
        "geco_update = jax.pmap(geco_update, axis_name='i', devices=jax.devices())\n",
        "\n",
        "geco_current_step = 0\n",
        "mses = []\n",
        "kls = []\n",
        "lag_muls = []\n",
        "\n",
        "geco_groups = {\n",
        "  'mse': ['mse'],\n",
        "  'kl': ['kl'],\n",
        "  'lag_mul': ['lag_mul'],\n",
        "}\n",
        "\n",
        "geco_plot = PlotLosses(\n",
        "    groups=geco_groups,\n",
        "    outputs=[MatplotlibPlot(max_cols=4, after_subplot=custom_after_subplot)], \n",
        "    step_names='Iterations')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjz1119u4mIM"
      },
      "source": [
        "for _ in range(TRAINING_STEPS):\n",
        "  geco_current_step += 1\n",
        "  params, prng_key, opt_state, stats = geco_update(\n",
        "      params, prng_key, opt_state, format_data(next(dataset)))\n",
        "  mse = stats[1]['mse'].mean()\n",
        "  kl = stats[1]['kl'].mean()\n",
        "  lag_mul = stats[1]['lag_mul'].mean()\n",
        "\n",
        "  geco_plot.update({\n",
        "      'mse': mse,\n",
        "      'kl': kl,\n",
        "      'lag_mul': lag_mul\n",
        "  })\n",
        "  if geco_current_step % PLOT_REFRESH_EVERY == 0:\n",
        "    geco_plot.send()\n",
        "  \n",
        "  mses.append(mse)\n",
        "  kls.append(kl) \n",
        "  lag_muls.append(lag_mul)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p1MfoWRqn6z"
      },
      "source": [
        "## Visualize reconstructions and samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVqlmUSfqE1C"
      },
      "source": [
        "targets, reconstructions, samples = reconstruct_and_sample(\n",
        "    params, prng_key, model,\n",
        "    next(get_dataset(batch_size=VIS_BATCH_SIZE, num_dev=1, hard=USE_HARD_DATA,\n",
        "                     data_split='test')))\n",
        "\n",
        "sz = 6\n",
        "_ = plt.figure(figsize=((3*sz, 1*sz)))\n",
        "plt.subplot(131)\n",
        "imshow(gallery(targets), 'Targets')\n",
        "plt.subplot(132)\n",
        "imshow(gallery(reconstructions), 'Reconstructions')\n",
        "plt.subplot(133)\n",
        "imshow(gallery(samples), 'Conditional samples');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ1fj8fYqymD"
      },
      "source": [
        "## Explore the latent space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRg8i4WgDjcM"
      },
      "source": [
        "dummy_data = get_dummy_data(hard=USE_HARD_DATA)\n",
        "num_steps = 7 * 7\n",
        "samples_from_interpolations = get_latent_interpolations(\n",
        "    model, get_slice(params), jax.random.PRNGKey(0), num_steps, dummy_data.context)\n",
        "\n",
        "sz = 6\n",
        "_ = plt.figure(figsize=((2*sz, sz)))\n",
        "plt.subplot(121)\n",
        "imshow(dummy_data.target[0,...], 'Label example')\n",
        "plt.subplot(122)\n",
        "imshow(gallery(samples_from_interpolations), 'Latent space interpolation')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}